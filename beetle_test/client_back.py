import asyncio
import logging
import os
import io
import base64
import json
from typing import List, Optional

import redis.asyncio as redis
import httpx
import requests
import aiofiles
from pydantic import BaseModel
from PIL import Image

from Prompt_loader import PromptLoader

# --- é…ç½® ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - [WORKER] - %(message)s')
logger = logging.getLogger(__name__)

# Ollama é…ç½®
OLLAMA_URL = "http://localhost:11434/api/generate"
OLLAMA_MODEL = "qwen3-vl:latest"
IMAGE_SAVE_DIR = "./workspace/images"
os.makedirs(IMAGE_SAVE_DIR, exist_ok=True)
SYSTEM_INSTRUCTION = PromptLoader("./promot/spill_promot.yaml")

# Redis é…ç½® (è¿žæŽ¥å®¿ä¸»æœº 6380)
REDIS_URL = "redis://localhost:6380"
TASK_QUEUE = "queue:missions"
RESULT_QUEUE = "queue:results"

# èµ„æºé”
GLOBAL_DOWNLOAD_SEM = asyncio.Semaphore(10)
GLOBAL_OLLAMA_LOCK = asyncio.Lock()


# --- æ•°æ®ç»“æž„ (éœ€ä¸ŽæœåŠ¡ç«¯ä¸€è‡´) ---

class PictureItem(BaseModel):
    picId: str
    dowmloadUrl: Optional[str] = None
    downloadUrl: Optional[str] = None

    def get_url(self):
        return self.dowmloadUrl or self.downloadUrl


class MissionRequest(BaseModel):
    taskSerial: str
    type: str
    callbackurl: str
    pictureList: List[PictureItem]


class CallbackItem(BaseModel):
    picId: str
    result: bool
    reason: str  # ç†ç”±å­—æ®µ


class CallbackPayload(BaseModel):
    taskSerial: str
    type: str
    data: List[CallbackItem]


class QueueItem:
    def __init__(self, pic_id: str, file_path: str, success: bool):
        self.pic_id = pic_id
        self.file_path = file_path
        self.success = success


# --- å›¾åƒå¤„ç†ä¸Žæ¨¡åž‹è°ƒç”¨ ---

def process_image_sync(file_path: str) -> str:
    try:
        img = Image.open(file_path)
        if img.mode != 'RGB':
            img = img.convert('RGB')
        # ä¿æŒæ¯”ä¾‹ç¼©æ”¾ï¼Œé™åˆ¶æœ€å¤§è¾¹é•¿ 640ï¼Œé˜²æ­¢æ˜¾å­˜æº¢å‡º
        img.thumbnail((640, 640), Image.Resampling.LANCZOS)
        buffered = io.BytesIO()
        img.save(buffered, format="JPEG", quality=85)
        return base64.b64encode(buffered.getvalue()).decode('utf-8')
    except Exception as e:
        logger.error(f"Img Error: {e}")
        return ""


def call_ollama_sync(image_base64: str, current_prompt: str):
    if not image_base64:
        logger.error("âŒ ABORTING: Image data is empty!")
        return False, "Image Error: No base64 data"

    # å¼ºåˆ¶è¦æ±‚æ ¼å¼
    user_task = "è¯·åˆ†æžå›¾åƒã€‚å¿…é¡»ä½¿ç”¨ä¸­æ–‡ä¸”ä¸¥æ ¼ä½¿ç”¨ä»¥ä¸‹æ ¼å¼å›žç­”ï¼š\nç†ç”±ï¼š[ä½ çš„ç†ç”±]\nç»“æžœï¼š[TRUEæˆ–FALSE]"
    payload = {
        "model": OLLAMA_MODEL,
        "system": current_prompt,
        "prompt": user_task,
        "images": [image_base64],
        "stream": False,
        "options": {
            "temperature": 0.0,
            "num_ctx": 6140,
            "top_p": 0.01
        }
    }

    # --- æ¢å¤ä½ çš„â€œå˜æ€â€æ£€æŸ¥æœºåˆ¶ ---
    try:
        # 1. å‘èµ·è¯·æ±‚
        response = requests.post(OLLAMA_URL, json=payload, timeout=120)

        # 2. çŠ¶æ€ç æ£€æŸ¥ (åŽŸæ±åŽŸå‘³)
        if response.status_code != 200:
            logger.critical(f"âŒ OLLAMA API ERROR: Status Code {response.status_code}")
            logger.error(f"âŒ Response Body: {response.text}")
            return False, f"HTTP Error {response.status_code}"

        # 3. è§£æžå“åº”
        response_json = response.json()
        if "response" not in response_json:
            logger.error(f"âŒ MALFORMED RESPONSE: Field 'response' missing. Keys: {response_json.keys()}")
            return False, "Protocol Error: Missing 'response' field"

        raw_text = response_json.get("response", "").strip()
        logger.info(f"ðŸ¤– Model Output: {raw_text}")

        # --- è§£æžé€»è¾‘ (ä¿æŒæ–°åŠŸèƒ½) ---
        result_bool = False
        if "TRUE" in raw_text.upper():
            result_bool = True
        elif "FALSE" in raw_text.upper():
            result_bool = False
        else:
            logger.warning(f"âš ï¸ AMBIGUOUS OUTPUT: Could not find TRUE/FALSE in: {raw_text[:50]}...")
            return False, f"Parse Error: {raw_text[:50]}"

        # æå–ç†ç”±
        reason_text = raw_text
        if "ç»“æžœï¼š" in reason_text:
            reason_text = reason_text.split("ç»“æžœï¼š")[0]
        elif "Result:" in reason_text:
            reason_text = reason_text.split("Result:")[0]

        clean_reason = reason_text.replace("ç†ç”±ï¼š", "").replace("Reason:", "").strip()
        if not clean_reason:
            clean_reason = "Model did not provide details."
        return result_bool, clean_reason

    # 4. ä¸“é—¨æ•èŽ·è¿žæŽ¥é”™è¯¯ (æ¢å¤ä½ çš„ Log é£Žæ ¼)
    except requests.exceptions.ConnectionError:
        logger.critical(f"âŒ CONNECTION DEAD: Could not connect to {OLLAMA_URL}.")
        logger.critical("âŒ CHECK: Is Ollama running? Is the port correct? Is Docker networking ok?")
        return False, "Connection Refused: Ollama Down"

    # 5. æ•èŽ·è¶…æ—¶
    except requests.exceptions.Timeout:
        logger.error(f"âŒ TIMEOUT: Ollama took longer than 120s to respond.")
        return False, "Timeout: Model too slow"

    # 6. æ•èŽ·å…¶ä»–æœªçŸ¥é”™è¯¯
    except Exception as e:
        logger.error(f"âŒ UNKNOWN CRASH in Inference: {str(e)}")
        return False, f"Exception: {str(e)}"
    # --- æ£€æŸ¥æœºåˆ¶ç»“æŸ ---


# --- ç”Ÿäº§æ¶ˆè´¹æµç¨‹ ---

async def producer(queue: asyncio.Queue, picture_list: List[PictureItem], taskSerial: str):
    async def download_one(client, pic):
        url = pic.get_url()
        if not url:
            await queue.put(QueueItem(pic.picId, "", False))
            return

        async with GLOBAL_DOWNLOAD_SEM:
            file_path = os.path.join(IMAGE_SAVE_DIR, f"{taskSerial}_{pic.picId}.jpg")
            # ç®€å•çš„é˜²é‡ä¸‹è½½é€»è¾‘ï¼Œå¯æ ¹æ®éœ€è¦ç§»é™¤
            if os.path.exists(file_path):
                await queue.put(QueueItem(pic.picId, file_path, True))
                return

            try:
                resp = await client.get(url, timeout=30.0)
                if resp.status_code == 200:
                    async with aiofiles.open(file_path, 'wb') as f:
                        await f.write(resp.content)
                    await queue.put(QueueItem(pic.picId, file_path, True))
                else:
                    await queue.put(QueueItem(pic.picId, "", False))
            except Exception as e:
                logger.error(f"Download error: {e}")
                await queue.put(QueueItem(pic.picId, "", False))

    async with httpx.AsyncClient(verify=False) as client:
        tasks = [download_one(client, pic) for pic in picture_list]
        await asyncio.gather(*tasks)
    await queue.put(None)


async def consumer(queue: asyncio.Queue, total_count: int, current_prompt: str) -> List[CallbackItem]:
    results = []
    processed_count = 0
    while processed_count < total_count:
        item = await queue.get()
        if item is None:
            break
        
        res_bool = False
        res_reason = "Download Failed"
        
        if item.success:
            b64 = await asyncio.to_thread(process_image_sync, item.file_path)
            if b64:
                async with GLOBAL_OLLAMA_LOCK:
                    logger.info(f"Inference: {item.pic_id}")
                    # è°ƒç”¨æ¨¡åž‹ï¼ŒèŽ·å– bool å’Œ string
                    res_bool, res_reason = await asyncio.to_thread(call_ollama_sync, b64, current_prompt)
            
            # åˆ å›¾
            try:
                os.remove(item.file_path)
            except:
                pass

        results.append(CallbackItem(picId=item.pic_id, result=res_bool, reason=res_reason))
        processed_count += 1
        queue.task_done()
    return results


async def process_mission(mission_data: str, redis_client):
    try:
        data = json.loads(mission_data)
        mission = MissionRequest(**data)

        logger.info(f"ðŸš€ Processing: {mission.taskSerial}")

        current_prompt = SYSTEM_INSTRUCTION.system_prompt_get(mission.type)
        queue = asyncio.Queue(maxsize=100)

        # å¯åŠ¨æ¶ˆè´¹è€…
        consumer_task = asyncio.create_task(consumer(queue, len(mission.pictureList), current_prompt))
        # å¯åŠ¨ç”Ÿäº§è€…
        await producer(queue, mission.pictureList, mission.taskSerial)

        # ç­‰å¾…ç»“æžœ
        final_data = await consumer_task

        # æž„é€ å›žè°ƒ Payload
        callback_payload = CallbackPayload(
            taskSerial=mission.taskSerial,
            type=mission.type,
            data=final_data
        )

        await redis_client.lpush(RESULT_QUEUE, callback_payload.json())
        logger.info(f"âœ… Done: {mission.taskSerial}")

    except Exception as e:
        logger.error(f"Mission Error: {e}")


async def main():
    redis_client = redis.from_url(REDIS_URL, decode_responses=True)
    logger.info("ðŸ”¥ Worker Node Started...")
    while True:
        try:
            result = await redis_client.brpop(TASK_QUEUE, timeout=0)
            if result:
                await process_mission(result[1], redis_client)
        except Exception as e:
            logger.error(f"Loop Error: {e}")
            await asyncio.sleep(5)


if __name__ == "__main__":
    asyncio.run(main())
